layout: post
title: "2018 빅콘테스트"
date: 2018-07-20 11:00:00
categories: Competition
author : DANBI
cover: "" 

# 2018 빅콘테스트

​	게임데이터는 현실과 매우 유사한 가상 세계에서 한 개체 (게임 캐릭터)의 모든 행동들이 기록된다는 점에서 높은 분석가치를 띄고있지만, 일반적으로 관련 회사에서 일하거나, 협약을 맺지 않는 이상, 게임데이터를 접하기는 쉽지 않습니다. 그렇기 때문에 엔씨소프트, 특히 저희 I&I실에서는 게임데이터를 공개하고, 게임 데이터에 대한 연구 활성화, 창의적인 분석 방법 그리고 발전을 위한 지식교류를 위해 항시 노력하고있습니다. 작년 (2017)에는 한국전자통신연구원(ETRI)와 세종대학교와 함께 게임 및 인공지능 관련 국제 학회인 IEEE CIG (Computation Intelligence and Amges)의 일환으로 데이터 분석 경진대회(https://cilab.sejong.ac.kr/gdmc2017/)를 개최하기도 했으며, 이러한 노력을 금년 (2018)에도 이어가고자 "2018 빅콘테스트"(http://bigcontest.or.kr/)의 주관사로 참가하게 되었습니다. 

​	올해로 벌써 6회째를 맞는 빅콘테스트는, 2013년부터 공공데이터 및 실제 기업에서 보유하고 있는 데이터를 학생 및 일반인에게 공개하여 데이터 분석능력을 겨루는 국대 최대규모의 데이터 분석 경진대회입니다. 매년 700개 이상의 팀이 참가하여 자신들의 데이터 분석 능력을 뽐내었고, 우수한 성과를 보인 팀은 상금 및 채용 기회 등의 큰 혜택을 제공받기도 했습니다. 이렇게 국내 최대 규모의 대회를, SK텔레콤, 신한은행, 신한카드와 더불어 엔씨소프트에서 올해 빅콘테스트를 주관하게 되었고, 엔씨소프트의 대표작 중 하나인 **블레이드 & 소울**의 데이터를 이용한 유저 이탈 예측 문제(챔피언리그)를 출제하게 되었습니다. 

![포스터](/assets/etc/bigcontest/poster.PNG)

​	이탈 예측은 게임업계뿐만이 아니라 통신, 은행 등 다양한 분야에서도 해지방어, 고객충성도 유지 등 각기 다른 명칭으로 불리우며 지대한 관심을 갖고 있는 문제입니다. 과거의 이력 (Signal)과 군입대, 여행, 출장과 같은 무작위성을 뛰는 개인사 및 외부적인요건 (Noise)이 존재하기 때문에, 오래전부터 데이터 분석가들의 사랑을 받아온 전형적인 데이터 분석/예측 문제이기도 합니다. 특히 신규 유저 유입 (User Acquisition)대비 기존 유저 잔존 (User Retention)이 효율적이라는 것이 여러 논문을 통해 확인이 되면서, "이탈예측을 통해 유저 잔존율 상승"의 중요성이 강조되고 있으며, 저희 실에서도 오래전부터 심도있게 연구하고, NDC(https://ndc.nexon.com/main) 발표도 진행했을 만큼 관심이 많은 분야입니다. 하지만, 이탈을 고려해야하는 기업 소속이 아니거나, 또는 관련 기업 소속이더라도 이탈 관련 업무를 처리하시지 않는 분들에게는 생소한 분야이기도 합니다. 그렇기 때문에, 이번 2018 빅콘테스트를 통해, 쉽게 접할수 없는 게임 데이터를 이용하여 많은 분들께서 이탈 예측을 진행해보는 기회가 되기를 기원합니다. 

​	분석작업을 진행하기 위해서는 분석의  대상, 데이터 분석을 통해서 확인할 가설 설정 등 작업들이 요구되는데요, 이탈예측또한 마찬가지입니다. 사실 이탈 예측을 하기 위해서는, 분석 대상 선정, 분석 기간 선정, 이탈의 정의 설정, 사용 데이터 구성 등 수도 없이 많은 정의 설정 및 사전 작업들이 요구됩니다. "2018 빅콘테스트"의 이탈예측 대회는 참가자분들의 편의를 위해 이러한  사전 작업들을 완료하여 제공하였기 때문에, 조금 더 쉽게 제공되는 데이터를 이용하여 이탈 예측 모델링을 진행 하실 수 있으리라 생각됩니다. 

​	이번 "2018 빅콘테스트"의 챔피언리그 주제인 이탈 예측을 진행하시는 분들을 위한 몇가지 팁을 드리며 글을 마무리짓고자 합니다. 

- 학교, 교과서 또는 온라인 수업에서 제공되는 비교적 작은 크기의 데이터에 비해 제공되는 데이터의 크기가 큰 편입니다 (몇몇 파일들은 500만 Row가 넘습니다). 고사양의 컴퓨터 또는 클러스터 사용이 가능하신 참가자분께는 전혀 문제가 없겠지만, 그렇지 못하리라 예상되는 대다수의 참가자분들께서는 효율적인 데이터 가공 방법과 중간 중간 가공된 데이터를 저장하면서 진행하는 것을 추천드립니다. 

- 이탈의 상태는 "Week", "Month" , "2Month", "Retained" 4가지로 분류되지만, 사실 크게보면 이탈 (Week, Month, 2Month)과 비이탈로 구분가능합니다. 이렇듯, 이탈자 비이탈자로 먼저 예측한뒤, 이탈자들을 다시  분류하는 등 다양한 방식 적용이 가능하니, 주어진 문제 그대로 "4개 클래스 예측"이라는 틀에 사로잡히기 보다는 다양한 방법들을 적용시켜보시기 바랍니다. 

- 페널데이터 형식을 띄는 데이터도 존재하기 때문에, 이를 감안하는 데이터 가공 또는 모델링 기법을 사용하는 것이 좋습니다. 

- 자율평가는 전체 평가 데이터의 20%만 사용하여 진행되기 때문에, 자율평가에 대한 과적합 (Overfitting)을 염두해야 합니다

- 모든 수치값들은 표준화 (Standardization)처리 되었기때문에, 테이블간 조인의 결과로 생성되는 *null* 또는 *NA*값을 0으로 기입하는 등의 실수를 조심해야 합니다. 

- 매주 수요일 정기점검이 있기 때문에, 한 주의 시작은 월요일이 아닌 수요일입니다.

- 모든 클래스를 고르게 잘 맞추는 모델을 선별하기 위해, 본 문제의 성능 측정 방식 (F1 score)은, 한 클래스를 전혀 맞추지 못하는 경우 0점이 나오도록 설정되었습니다. 

- 엔씨소프트의 "2018 빅콘테스트" 담당자들은 질문을 환영합니다. 

  











